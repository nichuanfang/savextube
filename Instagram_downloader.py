#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Instagram å›¾ç‰‡ä¸‹è½½å™¨ - ç®€åŒ–ç‰ˆæœ¬
ä½¿ç”¨å‘½ä»¤è¡Œæ–¹å¼è°ƒç”¨ gallery-dlï¼Œç¡®ä¿ cookies æ­£ç¡®ä¼ é€’
"""

import os
import sys
import time
import asyncio
import json
import logging
import subprocess
from pathlib import Path
from typing import Optional, Dict, Any, List
import requests
from urllib.parse import urlparse

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class InstagramPicDownloaderSimple:
    """Instagram å›¾ç‰‡ä¸‹è½½å™¨ - ç®€åŒ–ç‰ˆæœ¬"""
    
    def __init__(self, cookies_path: str = "./instagram_cookies.txt"):
        """
        åˆå§‹åŒ–ä¸‹è½½å™¨
        
        Args:
            cookies_path: Instagram cookies æ–‡ä»¶è·¯å¾„
        """
        self.cookies_path = cookies_path
        self.session = requests.Session()
        self._setup_session()
        
        # æ£€æŸ¥ gallery-dl æ˜¯å¦å¯ç”¨
        try:
            result = subprocess.run(['gallery-dl', '--version'], 
                                  capture_output=True, text=True, check=True)
            self.gallery_dl_available = True
            logger.info(f"âœ… gallery-dl å¯ç”¨ï¼Œç‰ˆæœ¬: {result.stdout.strip()}")
        except (subprocess.CalledProcessError, FileNotFoundError):
            self.gallery_dl_available = False
            logger.error("âŒ gallery-dl æœªå®‰è£…æˆ–ä¸å¯ç”¨")
    
    def _setup_session(self):
        """è®¾ç½®ä¼šè¯å’Œ cookies"""
        try:
            # è®¾ç½® User-Agent
            self.session.headers.update({
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Language': 'en-US,en;q=0.5',
                'Accept-Encoding': 'gzip, deflate',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
            })
            
            # åŠ è½½ cookies
            if os.path.exists(self.cookies_path):
                logger.info(f"ğŸ“„ åŠ è½½ Instagram cookies: {self.cookies_path}")
                self._load_cookies()
            else:
                logger.warning(f"âš ï¸ Instagram cookies æ–‡ä»¶ä¸å­˜åœ¨: {self.cookies_path}")
                
        except Exception as e:
            logger.error(f"âŒ è®¾ç½®ä¼šè¯å¤±è´¥: {e}")
    
    def _load_cookies(self):
        """åŠ è½½ cookies æ–‡ä»¶"""
        try:
            with open(self.cookies_path, 'r', encoding='utf-8') as f:
                cookies_data = f.read().strip()
            
            # è§£æ cookies æ ¼å¼ï¼ˆå‡è®¾æ˜¯ Netscape æ ¼å¼ï¼‰
            for line in cookies_data.split('\n'):
                if line.strip() and not line.startswith('#'):
                    parts = line.split('\t')
                    if len(parts) >= 7:
                        domain = parts[0]
                        flag = parts[1]
                        path = parts[2]
                        secure = parts[3]
                        expiry = parts[4]
                        name = parts[5]
                        value = parts[6]
                        
                        if domain.endswith('instagram.com'):
                            self.session.cookies.set(name, value, domain=domain, path=path)
            
            logger.info(f"âœ… æˆåŠŸåŠ è½½ Instagram cookies")
            
        except Exception as e:
            logger.error(f"âŒ åŠ è½½ cookies å¤±è´¥: {e}")
    
    def is_instagram_url(self, url: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸º Instagram URL"""
        instagram_domains = [
            'instagram.com',
            'www.instagram.com',
            'm.instagram.com',
            'web.instagram.com'
        ]
        
        try:
            parsed = urlparse(url)
            return any(domain in parsed.netloc for domain in instagram_domains)
        except:
            return False
    
    def extract_post_id(self, url: str) -> Optional[str]:
        """ä» Instagram URL ä¸­æå–å¸–å­ ID"""
        try:
            # æ”¯æŒå¤šç§ Instagram URL æ ¼å¼
            if '/p/' in url:
                # å¸–å­æ ¼å¼: https://www.instagram.com/p/ABC123/
                post_id = url.split('/p/')[1].split('/')[0]
            elif '/reel/' in url:
                # Reel æ ¼å¼: https://www.instagram.com/reel/ABC123/
                post_id = url.split('/reel/')[1].split('/')[0]
            elif '/tv/' in url:
                # IGTV æ ¼å¼: https://www.instagram.com/tv/ABC123/
                post_id = url.split('/tv/')[1].split('/')[0]
            else:
                return None
            
            return post_id
        except:
            return None
    
    async def download_post(self, url: str, download_dir: str = "./downloads", progress_callback=None) -> Dict[str, Any]:
        """
        ä¸‹è½½ Instagram å¸–å­
        
        Args:
            url: Instagram å¸–å­ URL
            download_dir: ä¸‹è½½ç›®å½•
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            
        Returns:
            ä¸‹è½½ç»“æœå­—å…¸
        """
        try:
            if not self.gallery_dl_available:
                return {
                    "success": False,
                    "error": "gallery-dl æœªå®‰è£…æˆ–ä¸å¯ç”¨"
                }
            
            # æ£€æŸ¥ URL æ ¼å¼
            if not self.is_instagram_url(url):
                return {
                    "success": False,
                    "error": "ä¸æ˜¯æœ‰æ•ˆçš„ Instagram URL"
                }
            
            # æå–å¸–å­ ID
            post_id = self.extract_post_id(url)
            if not post_id:
                return {
                    "success": False,
                    "error": "æ— æ³•ä» URL ä¸­æå–å¸–å­ ID"
                }
            
            logger.info(f"ğŸ“± å¼€å§‹ä¸‹è½½ Instagram å¸–å­: {post_id}")
            
            # åˆ›å»ºä¸‹è½½ç›®å½•
            os.makedirs(download_dir, exist_ok=True)
            
            # å‘é€å¼€å§‹ä¸‹è½½æ¶ˆæ¯
            if progress_callback:
                start_text = (
                    f"ğŸš€ å¼€å§‹ä¸‹è½½ Instagram å¸–å­\n"
                    f"ğŸ“ å¸–å­ ID: `{post_id}`\n"
                    f"ğŸ“¥ æ­£åœ¨è·å–åª’ä½“ä¿¡æ¯..."
                )
                await self._safe_callback(progress_callback, start_text)
            
            # ä½¿ç”¨å‘½ä»¤è¡Œæ–¹å¼è°ƒç”¨ gallery-dl
            result = await self._download_with_gallery_dl_cmd(url, download_dir, progress_callback, post_id)
            
            if result.get("success"):
                logger.info(f"âœ… Instagram å¸–å­ä¸‹è½½æˆåŠŸ: {post_id}")
                return {
                    "success": True,
                    "post_id": post_id,
                    "url": url,
                    "platform": "Instagram",
                    "content_type": "image",
                    "download_path": result.get("download_path", download_dir),
                    "files": result.get("files", []),
                    "files_count": result.get("files_count", 0),
                    "total_size": result.get("total_size", 0),
                    "file_formats": result.get("file_formats", [])
                }
            else:
                logger.error(f"âŒ Instagram å¸–å­ä¸‹è½½å¤±è´¥: {result.get('error')}")
                return result
                
        except Exception as e:
            logger.error(f"âŒ ä¸‹è½½ Instagram å¸–å­å¤±è´¥: {e}")
            return {
                "success": False,
                "error": f"ä¸‹è½½å¤±è´¥: {str(e)}"
            }
    
    async def _download_with_gallery_dl_cmd(self, url: str, download_dir: str, progress_callback=None, post_id=None) -> Dict[str, Any]:
        """ä½¿ç”¨å‘½ä»¤è¡Œæ–¹å¼è°ƒç”¨ gallery-dl ä¸‹è½½"""
        try:
            # è®°å½•ä¸‹è½½å‰çš„æ–‡ä»¶
            before_files = set()
            download_path = Path(download_dir)
            if download_path.exists():
                for file_path in download_path.rglob("*"):
                    if file_path.is_file():
                        relative_path = str(file_path.relative_to(download_path))
                        before_files.add(relative_path)
            
            logger.info(f"ğŸ“Š ä¸‹è½½å‰æ–‡ä»¶æ•°é‡: {len(before_files)}")
            
            # åˆ›å»ºè¿›åº¦ç›‘æ§ä»»åŠ¡
            progress_task = None
            if progress_callback:
                progress_task = asyncio.create_task(self._monitor_progress(
                    download_path, before_files, progress_callback
                ))
            
            # æ„å»º gallery-dl å‘½ä»¤
            cmd = [
                'gallery-dl',
                '--cookies', self.cookies_path,
                '--dest', download_dir,
                '--verbose',
                url
            ]
            
            logger.info(f"ğŸ“¸ æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
            
            # åœ¨å¼‚æ­¥æ‰§è¡Œå™¨ä¸­è¿è¡Œå‘½ä»¤
            def run_gallery_dl():
                return subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
            
            loop = asyncio.get_running_loop()
            process = await loop.run_in_executor(None, run_gallery_dl)
            
            logger.info(f"ğŸ“¸ gallery-dl å‘½ä»¤æ‰§è¡Œå®Œæˆï¼Œè¿”å›ç : {process.returncode}")
            
            if process.stdout:
                logger.info(f"ğŸ“¸ æ ‡å‡†è¾“å‡º: {process.stdout[:500]}...")
            if process.stderr:
                logger.warning(f"ğŸ“¸ æ ‡å‡†é”™è¯¯: {process.stderr[:500]}...")
            
            # ç­‰å¾…æ–‡ä»¶å†™å…¥å®Œæˆ
            await asyncio.sleep(3)
            
            # å–æ¶ˆè¿›åº¦ç›‘æ§ä»»åŠ¡
            if progress_task:
                progress_task.cancel()
                try:
                    await progress_task
                except asyncio.CancelledError:
                    pass
            
            # è®¡ç®—ä¸‹è½½ç»“æœ
            current_files = set()
            if download_path.exists():
                for file_path in download_path.rglob("*"):
                    if file_path.is_file():
                        relative_path = str(file_path.relative_to(download_path))
                        current_files.add(relative_path)
            
            new_files = current_files - before_files
            files_count = len(new_files)
            
            if files_count == 0:
                return {
                    "success": False,
                    "error": f"æ²¡æœ‰ä¸‹è½½åˆ°ä»»ä½•æ–‡ä»¶ (å‘½ä»¤è¿”å›ç : {process.returncode})"
                }
            
            # è®¡ç®—æ€»å¤§å°å’Œæ–‡ä»¶æ ¼å¼
            total_size = 0
            file_formats = set()
            files_info = []
            
            for file_path in new_files:
                full_path = download_path / file_path
                if full_path.exists():
                    file_size = full_path.stat().st_size
                    total_size += file_size
                    
                    # æå–æ–‡ä»¶æ ¼å¼
                    ext = full_path.suffix.lower().lstrip('.')
                    if ext:
                        file_formats.add(ext.upper())
                    
                    files_info.append({
                        'path': str(full_path),
                        'size': file_size,
                        'filename': full_path.name
                    })
            
            # å‘é€å®Œæˆæ¶ˆæ¯
            if progress_callback:
                final_text = (
                    f"âœ… Instagram å¸–å­ä¸‹è½½å®Œæˆ\n"
                    f"ğŸ“ å¸–å­ ID: `{post_id}`\n"
                    f"ğŸ–¼ï¸ æ–‡ä»¶æ•°é‡: `{files_count} ä¸ª`\n"
                    f"ğŸ’¾ æ€»å¤§å°: `{total_size / (1024*1024):.2f} MB`\n"
                    f"ğŸ“„ æ–‡ä»¶æ ¼å¼: `{', '.join(file_formats)}`"
                )
                await self._safe_callback(progress_callback, final_text)
            
            return {
                "success": True,
                "files_count": files_count,
                "total_size": total_size,
                "file_formats": list(file_formats),
                "files": files_info,
                "download_path": str(download_path)
            }
            
        except Exception as e:
            logger.error(f"âŒ gallery-dl å‘½ä»¤æ‰§è¡Œå¤±è´¥: {e}")
            return {
                "success": False,
                "error": f"gallery-dl å‘½ä»¤æ‰§è¡Œå¤±è´¥: {str(e)}"
            }
    
    async def _monitor_progress(self, download_path: Path, before_files: set, progress_callback):
        """ç›‘æ§ä¸‹è½½è¿›åº¦"""
        try:
            last_count = 0
            last_update_time = time.time()
            update_interval = 2  # æ¯2ç§’æ›´æ–°ä¸€æ¬¡è¿›åº¦
            
            logger.info(f"ğŸ“Š å¼€å§‹ç›‘æ§ Instagram ä¸‹è½½è¿›åº¦")
            
            while True:
                await asyncio.sleep(1)  # æ¯1ç§’æ£€æŸ¥ä¸€æ¬¡
                
                # è®¡ç®—å½“å‰æ–‡ä»¶æ•°é‡
                current_files = set()
                if download_path.exists():
                    for file_path in download_path.rglob("*"):
                        if file_path.is_file():
                            relative_path = str(file_path.relative_to(download_path))
                            current_files.add(relative_path)
                
                # è®¡ç®—æ–°æ–‡ä»¶æ•°é‡
                new_files = current_files - before_files
                current_count = len(new_files)
                
                # å¦‚æœæ–‡ä»¶æ•°é‡æœ‰å˜åŒ–æˆ–æ—¶é—´é—´éš”åˆ°äº†ï¼Œæ›´æ–°è¿›åº¦
                if current_count != last_count or time.time() - last_update_time > update_interval:
                    last_count = current_count
                    last_update_time = time.time()
                    
                    # è·å–å½“å‰æ­£åœ¨ä¸‹è½½çš„æ–‡ä»¶è·¯å¾„
                    current_file_path = "å‡†å¤‡ä¸­..."
                    if new_files:
                        latest_file = sorted(new_files)[-1]
                        current_file_path = latest_file
                    
                    progress_text = (
                        f"ğŸ“± **Instagram å›¾ç‰‡ä¸‹è½½ä¸­**\n"
                        f"ğŸ“ å½“å‰ä¸‹è½½ï¼š`{current_file_path}`\n"
                        f"ğŸ–¼ï¸ å·²å®Œæˆï¼š{current_count} ä¸ª"
                    )
                    
                    await self._safe_callback(progress_callback, progress_text)
                    
        except asyncio.CancelledError:
            logger.info("ğŸ“Š è¿›åº¦ç›‘æ§ä»»åŠ¡å·²å–æ¶ˆ")
        except Exception as e:
            logger.error(f"âŒ è¿›åº¦ç›‘æ§ä»»åŠ¡é”™è¯¯: {e}")
    
    async def _safe_callback(self, callback, text):
        """å®‰å…¨è°ƒç”¨å›è°ƒå‡½æ•°"""
        try:
            if asyncio.iscoroutinefunction(callback):
                await callback(text)
            else:
                callback(text)
        except Exception as e:
            logger.warning(f"âš ï¸ å›è°ƒå‡½æ•°è°ƒç”¨å¤±è´¥: {e}")

async def main():
    """ä¸»å‡½æ•° - ç”¨äºæµ‹è¯•"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Instagram å›¾ç‰‡ä¸‹è½½å™¨ - ç®€åŒ–ç‰ˆæœ¬')
    parser.add_argument('urls', nargs='*', help='è¦ä¸‹è½½çš„ Instagram é“¾æ¥')
    parser.add_argument('-d', '--dir', default='./downloads', help='ä¸‹è½½ç›®å½•')
    parser.add_argument('-c', '--cookies', default='./instagram_cookies.txt', help='Instagram Cookies æ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    
    downloader = InstagramPicDownloaderSimple(cookies_path=args.cookies)
    
    # å¦‚æœæ²¡æœ‰é€šè¿‡å‘½ä»¤è¡Œæä¾›URLï¼Œä½¿ç”¨äº¤äº’å¼è¾“å…¥
    urls = args.urls
    if not urls:
        print("è¯·è¾“å…¥ Instagram é“¾æ¥ï¼ˆè¾“å…¥ 'quit' é€€å‡ºï¼‰:")
        while True:
            url = input("URL: ").strip()
            if url.lower() == 'quit':
                break
            if url:
                urls.append(url)
    
    if not urls:
        print("æ²¡æœ‰æä¾›ä»»ä½•é“¾æ¥")
        return
    
    print(f"å‡†å¤‡ä¸‹è½½ {len(urls)} ä¸ª Instagram é“¾æ¥åˆ°ç›®å½•: {args.dir}")
    
    # åˆ›å»ºç®€å•çš„è¿›åº¦å›è°ƒå‡½æ•°
    async def progress_callback(text):
        print(f"ğŸ“± è¿›åº¦: {text}")
    
    success_count = 0
    for i, url in enumerate(urls, 1):
        try:
            print(f"\n[{i}/{len(urls)}] å¤„ç†é“¾æ¥: {url}")
            
            result = await downloader.download_post(url, args.dir, progress_callback)
            if result.get("success"):
                success_count += 1
                print(f"âœ… ä¸‹è½½æˆåŠŸ: {result.get('post_id', 'æœªçŸ¥å¸–å­')}")
            else:
                print(f"âŒ ä¸‹è½½å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            
            time.sleep(2)  # é¿å…è¯·æ±‚è¿‡å¿«
        except Exception as e:
            print(f"å¤„ç†é“¾æ¥å¤±è´¥ {url}: {e}")
    
    print(f"\nå®Œæˆï¼æˆåŠŸä¸‹è½½ {success_count}/{len(urls)} ä¸ªé“¾æ¥")

if __name__ == "__main__":
    asyncio.run(main())

