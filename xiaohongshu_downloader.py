#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°çº¢ä¹¦å›¾ç‰‡ä¸‹è½½å™¨ - Python ç‰ˆæœ¬
åŸºäºç”¨æˆ·è„šæœ¬çš„è½»é‡çº§å®ç°æ€è·¯
"""

import re
import json
import requests
import os
import asyncio
from pathlib import Path
from urllib.parse import urlparse
import time
from typing import List, Dict, Optional

class XiaohongshuDownloader:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        })
        
    def _expand_short_url(self, url: str) -> Optional[str]:
        """å±•å¼€çŸ­é“¾æ¥ä¸ºå®Œæ•´URL"""
        original_url = url
        
        # æ¸…ç†URLï¼Œç§»é™¤æœ«å°¾çš„æ— å…³å­—ç¬¦
        url = url.strip().split(' ')[0]  # ç§»é™¤ç©ºæ ¼åçš„å†…å®¹
        print(f"ğŸ”§ æ¸…ç†åçš„URL: {url}")
        
        # å¦‚æœæ˜¯çŸ­é“¾æ¥ï¼Œå…ˆå±•å¼€
        if 'xhslink.com' in url:
            try:
                print(f"ğŸ”„ æ­£åœ¨å±•å¼€çŸ­é“¾æ¥: {url}")
                
                # è®¾ç½®æ›´å®Œæ•´çš„è¯·æ±‚å¤´ï¼Œæ¨¡æ‹ŸçœŸå®æµè§ˆå™¨
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
                    'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                    'Accept-Encoding': 'gzip, deflate, br',
                    'Connection': 'keep-alive',
                    'Upgrade-Insecure-Requests': '1',
                    'Sec-Fetch-Dest': 'document',
                    'Sec-Fetch-Mode': 'navigate',
                    'Sec-Fetch-Site': 'none',
                    'Cache-Control': 'max-age=0',
                    'Referer': 'https://www.xiaohongshu.com/',
                    'sec-ch-ua': '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
                    'sec-ch-ua-mobile': '?0',
                    'sec-ch-ua-platform': '"macOS"'
                }
                
                # å°è¯•å¤šæ¬¡é‡å®šå‘
                max_redirects = 5
                current_url = url
                
                for redirect_count in range(max_redirects):
                    try:
                        print(f"ğŸ”„ ç¬¬ {redirect_count + 1} æ¬¡è¯·æ±‚: {current_url}")
                        response = self.session.get(current_url, headers=headers, allow_redirects=False, timeout=15)
                        
                        if response.status_code in [301, 302, 307, 308]:
                            # å¤„ç†é‡å®šå‘
                            location = response.headers.get('Location')
                            if location:
                                if location.startswith('/'):
                                    # ç›¸å¯¹è·¯å¾„ï¼Œéœ€è¦æ„å»ºå®Œæ•´URL
                                    parsed = urlparse(current_url)
                                    location = f"{parsed.scheme}://{parsed.netloc}{location}"
                                current_url = location
                                print(f"ğŸ”„ é‡å®šå‘åˆ°: {current_url}")
                                
                                # æ£€æŸ¥æ˜¯å¦é‡å®šå‘åˆ°äº†é€šç”¨é¡µé¢
                                if '/explore' in current_url or current_url == 'https://www.xiaohongshu.com':
                                    print(f"âš ï¸ é‡å®šå‘åˆ°é€šç”¨é¡µé¢ï¼Œå¯èƒ½çŸ­é“¾æ¥å·²è¿‡æœŸ")
                                    break
                                continue
                        elif response.status_code == 200:
                            # æˆåŠŸè·å–é¡µé¢
                            break
                        else:
                            print(f"âš ï¸ è¯·æ±‚çŠ¶æ€ç : {response.status_code}")
                            break
                            
                    except Exception as e:
                        print(f"âš ï¸ ç¬¬ {redirect_count + 1} æ¬¡è¯·æ±‚å¤±è´¥: {e}")
                        break
                
                # è¿”å›æœ€ç»ˆå±•å¼€çš„é“¾æ¥
                if current_url != original_url and '/explore' not in current_url and current_url != 'https://www.xiaohongshu.com':
                    print(f"âœ… çŸ­é“¾æ¥å±•å¼€æˆåŠŸ: {current_url}")
                    return current_url
                else:
                    print(f"âš ï¸ çŸ­é“¾æ¥å±•å¼€å¤±è´¥æˆ–é‡å®šå‘åˆ°é€šç”¨é¡µé¢")
                    print(f"âŒ æ— æ³•å±•å¼€çŸ­é“¾æ¥ï¼Œè¯·æ£€æŸ¥é“¾æ¥æ˜¯å¦æœ‰æ•ˆ")
                    return None
                    
            except Exception as e:
                print(f"âŒ çŸ­é“¾æ¥å±•å¼€å¤±è´¥: {e}")
                print(f"âš ï¸ å°†ä½¿ç”¨åŸå§‹URLç»§ç»­å¤„ç†")
                return None
        
        # å¦‚æœä¸æ˜¯çŸ­é“¾æ¥ï¼Œç›´æ¥è¿”å›åŸURL
        return url
    


    def extract_note_id(self, url: str) -> Optional[str]:
        """ä»URLä¸­æå–ç¬”è®°ID"""
        # å…ˆå±•å¼€çŸ­é“¾æ¥
        expanded_url = self._expand_short_url(url)
        
        # å¦‚æœçŸ­é“¾æ¥å±•å¼€å¤±è´¥ï¼Œç›´æ¥è¿”å›None
        if not expanded_url:
            print(f"âŒ çŸ­é“¾æ¥å±•å¼€å¤±è´¥ï¼Œæ— æ³•æå–ç¬”è®°ID")
            return None
        
        # å°è¯•å¤šç§æ¨¡å¼æå–ç¬”è®°ID
        patterns = [
            r'/explore/([^?]+)',
            r'/discovery/item/([^?]+)',
            r'noteId=([^&]+)',
            r'/item/([^?]+)',
            r'xhslink\.com/m/([^?]+)',  # çŸ­é“¾æ¥æ¨¡å¼
        ]
        
        for pattern in patterns:
            match = re.search(pattern, expanded_url)
            if match:
                note_id = match.group(1)
                print(f"âœ… æå–åˆ°ç¬”è®°ID: {note_id}")
                return note_id
        
        print(f"âŒ æ— æ³•ä»URLæå–ç¬”è®°ID: {expanded_url}")
        return None
    
    def get_page_data(self, url: str) -> Optional[Dict]:
        """è·å–é¡µé¢æ•°æ®ï¼Œæå– __INITIAL_STATE__"""
        try:
            print(f"ğŸ” æ­£åœ¨è·å–é¡µé¢æ•°æ®: {url}")
            
            # è®¾ç½®æ›´å®Œæ•´çš„è¯·æ±‚å¤´ï¼Œæ¨¡æ‹ŸçœŸå®æµè§ˆå™¨
            headers = {
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
                'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                'Accept-Encoding': 'gzip, deflate, br',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
                'Sec-Fetch-Dest': 'document',
                'Sec-Fetch-Mode': 'navigate',
                'Sec-Fetch-Site': 'none',
                'Cache-Control': 'max-age=0',
                'Referer': 'https://www.xiaohongshu.com/',
                'sec-ch-ua': '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
                'sec-ch-ua-mobile': '?0',
                'sec-ch-ua-platform': '"macOS"'
            }
            
            # ç›´æ¥è·å–é¡µé¢ï¼Œä¸é‡è¯•
            response = self.session.get(url, headers=headers, timeout=15)
            response.raise_for_status()
            
            print(f"âœ… é¡µé¢è·å–æˆåŠŸ: çŠ¶æ€ç  {response.status_code}, å¤§å° {len(response.text)} å­—ç¬¦")

            # å°è¯•æå– __INITIAL_STATE__ æ•°æ®
            patterns = [
                r'window\.__INITIAL_STATE__\s*=\s*({.+?})</script>',
                r'__INITIAL_STATE__\s*=\s*({.+?})</script>',
            ]

            for i, pattern in enumerate(patterns):
                match = re.search(pattern, response.text, re.DOTALL)
                if match:
                    try:
                        print(f"âœ… ä½¿ç”¨æ¨¡å¼ {i+1} æ‰¾åˆ°æ•°æ®")
                        json_str = match.group(1).strip()
                        
                        # ç®€å•çš„JSONæ¸…ç†
                        json_str = json_str.replace('undefined', 'null')
                        
                        # ç›´æ¥è§£æ
                        data = json.loads(json_str)
                        print(f"âœ… JSONè§£ææˆåŠŸ")
                        return data
                        
                    except json.JSONDecodeError as e:
                        print(f"âš ï¸ æ¨¡å¼ {i+1} JSONè§£æå¤±è´¥: {e}")
                        continue

            # å¦‚æœéƒ½æ²¡æ‰¾åˆ°
            if '__INITIAL_STATE__' in response.text:
                print("âš ï¸ é¡µé¢åŒ…å« __INITIAL_STATE__ ä½†æ— æ³•è§£æ")
            else:
                print("âŒ é¡µé¢ä¸åŒ…å« __INITIAL_STATE__ æ•°æ®")

            return None

        except Exception as e:
            print(f"âŒ è·å–é¡µé¢æ•°æ®æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
            return None
    
    def _smart_fix_json(self, json_str: str) -> Optional[str]:
        """æ™ºèƒ½ä¿®å¤JSONè¯­æ³•é”™è¯¯"""
        try:
            print(f"ğŸ”§ å¼€å§‹æ™ºèƒ½ä¿®å¤JSONï¼Œé•¿åº¦: {len(json_str)}")
            
            # æ–¹æ³•1ï¼šå°è¯•ä¿®å¤å°¾éšé€—å·
            fixed = re.sub(r',(\s*[}\]])', r'\1', json_str)
            
            # æ–¹æ³•2ï¼šå°è¯•ä¿®å¤ undefined
            fixed = fixed.replace('undefined', 'null')
            
            # æ–¹æ³•3ï¼šå°è¯•ä¿®å¤ null,
            fixed = fixed.replace('null,', '')
            
            # æ–¹æ³•4ï¼šå°è¯•ä¿®å¤å¤šä½™çš„é€—å·
            fixed = re.sub(r',+', ',', fixed)
            
            # æ–¹æ³•5ï¼šå°è¯•ä¿®å¤å¼•å·é—®é¢˜
            fixed = fixed.replace('\\u002F', '/')
            fixed = fixed.replace('\\"', '"')
            
            # æ–¹æ³•6ï¼šå°è¯•ä¿®å¤å¯èƒ½çš„è¯­æ³•é”™è¯¯
            # æŸ¥æ‰¾å¹¶ä¿®å¤å¸¸è§çš„è¯­æ³•é”™è¯¯
            try:
                # å…ˆå°è¯•ç›´æ¥è§£æ
                json.loads(fixed)
                print(f"âœ… æ™ºèƒ½ä¿®å¤æˆåŠŸ")
                return fixed
            except json.JSONDecodeError as e:
                print(f"âš ï¸ æ™ºèƒ½ä¿®å¤åä»æœ‰é”™è¯¯: {e}")
                
                # å°è¯•æ›´æ¿€è¿›çš„ä¿®å¤
                # æŸ¥æ‰¾é”™è¯¯ä½ç½®é™„è¿‘çš„å†…å®¹
                error_pos = e.pos
                print(f"ğŸ” é”™è¯¯ä½ç½®: {error_pos}")
                
                # æ˜¾ç¤ºé”™è¯¯ä½ç½®é™„è¿‘çš„å†…å®¹
                start = max(0, error_pos - 100)
                end = min(len(fixed), error_pos + 100)
                print(f"ğŸ” é”™è¯¯é™„è¿‘å†…å®¹: {fixed[start:end]}")
                
                # å°è¯•ä¿®å¤å¸¸è§çš„è¯­æ³•é”™è¯¯
                # 1. ä¿®å¤ç¼ºå°‘çš„å¼•å·
                fixed = re.sub(r'([{,])\s*([a-zA-Z_][a-zA-Z0-9_]*)\s*:', r'\1"\2":', fixed)
                
                # 2. ä¿®å¤ç¼ºå°‘çš„é€—å·
                fixed = re.sub(r'(["\d])\s*([a-zA-Z_][a-zA-Z0-9_]*)\s*:', r'\1,\2":', fixed)
                
                # 3. å°è¯•è§£æä¿®å¤åçš„JSON
                try:
                    json.loads(fixed)
                    print(f"âœ… æ¿€è¿›ä¿®å¤æˆåŠŸ")
                    return fixed
                except:
                    print(f"âŒ æ¿€è¿›ä¿®å¤ä¹Ÿå¤±è´¥äº†")
                    return None
                    
        except Exception as e:
            print(f"âŒ æ™ºèƒ½ä¿®å¤è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return None
    
    def extract_note_info(self, data: Dict, note_id: str) -> Optional[Dict]:
        """ä»é¡µé¢æ•°æ®ä¸­æå–ç¬”è®°ä¿¡æ¯"""
        try:
            print(f"ğŸ” å¼€å§‹æå–ç¬”è®°ä¿¡æ¯ï¼Œç¬”è®°ID: {note_id}")
            print(f"ğŸ” æ•°æ®é¡¶å±‚é”®: {list(data.keys())}")
            
            # å°è¯•ä¸åŒçš„æ•°æ®è·¯å¾„
            paths = [
                f"note.noteDetailMap.{note_id}.note",
                f"note.noteDetailMap.{note_id}",
                f"feed.feeds",
                f"note.noteDetailMap",
                f"feed",
            ]
            
            for path in paths:
                print(f"ğŸ” å°è¯•è·¯å¾„: {path}")
                current = data
                for key in path.split('.'):
                    if key in current:
                        current = current[key]
                        print(f"ğŸ” æ‰¾åˆ°é”® {key}ï¼Œç±»å‹: {type(current)}")
                    else:
                        print(f"âš ï¸ é”® {key} ä¸å­˜åœ¨")
                        current = None
                        break
                
                if current:
                    print(f"ğŸ” è·¯å¾„ {path} æ•°æ®: {type(current)}")
                    
                    # å¦‚æœcurrentæ˜¯åˆ—è¡¨ï¼Œå°è¯•æ‰¾åˆ°åŒ…å«note_idçš„é¡¹
                    if isinstance(current, list):
                        print(f"ğŸ” æ‰¾åˆ°åˆ—è¡¨æ•°æ®ï¼Œé•¿åº¦: {len(current)}")
                        if len(current) > 0:
                            print(f"ğŸ” ç¬¬ä¸€ä¸ªåˆ—è¡¨é¡¹é”®: {list(current[0].keys()) if isinstance(current[0], dict) else 'éå­—å…¸'}")
                        
                        for i, item in enumerate(current):
                            if isinstance(item, dict):
                                item_id = item.get('id') or item.get('noteId') or item.get('note_id')
                                print(f"ğŸ” æ£€æŸ¥åˆ—è¡¨é¡¹ {i}: id={item_id}, ç±»å‹={type(item_id)}")
                                if str(item_id) == str(note_id):
                                    print(f"âœ… åœ¨åˆ—è¡¨ä¸­æ‰¾åˆ°åŒ¹é…çš„ç¬”è®°: {note_id}")
                                    # å¦‚æœæ‰¾åˆ°åŒ¹é…çš„é¡¹ï¼Œå°è¯•æå–noteCard
                                    if 'noteCard' in item:
                                        print(f"ğŸ” æ‰¾åˆ°noteCardå­—æ®µ")
                                        return item['noteCard']
                                    return item
                        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„ï¼Œç»§ç»­å°è¯•ä¸‹ä¸€ä¸ªè·¯å¾„
                        print(f"âš ï¸ åœ¨è·¯å¾„ {path} ä¸­æœªæ‰¾åˆ°åŒ¹é…çš„ç¬”è®°ID: {note_id}")
                        continue
                    else:
                        print(f"ğŸ” è¿”å›éåˆ—è¡¨æ•°æ®: {type(current)}")
                        return current
            
            print(f"âŒ åœ¨æ‰€æœ‰æ•°æ®è·¯å¾„ä¸­éƒ½æœªæ‰¾åˆ°ç¬”è®°ID: {note_id}")
            return None
            
        except Exception as e:
            print(f"æå–ç¬”è®°ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    def generate_image_urls(self, note: Dict) -> List[str]:
        """ç”Ÿæˆæ— æ°´å°å›¾ç‰‡é“¾æ¥"""
        urls = []
        
        try:
            images = note.get('imageList', [])
            
            for item in images:
                url_default = item.get('urlDefault', '')
                
                # ä½¿ç”¨æ­£åˆ™æå–å›¾ç‰‡IDï¼ˆæ¨¡ä»¿ç”¨æˆ·è„šæœ¬çš„é€»è¾‘ï¼‰
                pattern = r'http://sns-webpic-qc\.xhscdn\.com/\d+/[0-9a-z]+/(\S+)!'
                match = re.search(pattern, url_default)
                
                if match:
                    image_id = match.group(1)
                    # æ„é€ æ— æ°´å°é“¾æ¥
                    clean_url = f"https://ci.xiaohongshu.com/{image_id}?imageView2/format/png"
                    urls.append(clean_url)
                else:
                    # å¤‡ç”¨æ–¹æ¡ˆï¼šå°è¯•å…¶ä»–å¯èƒ½çš„é“¾æ¥æ ¼å¼
                    for key in ['urlDefault', 'url', 'picUrl']:
                        if key in item and item[key]:
                            urls.append(item[key])
                            break
            
            return urls
            
        except Exception as e:
            print(f"ç”Ÿæˆå›¾ç‰‡é“¾æ¥å¤±è´¥: {e}")
            return []
    
    def generate_video_url(self, note: Dict) -> List[str]:
        """ç”Ÿæˆè§†é¢‘é“¾æ¥"""
        try:
            video_key = note.get('video', {}).get('consumer', {}).get('originVideoKey')
            if video_key:
                return [f"https://sns-video-bd.xhscdn.com/{video_key}"]
            return []
        except Exception as e:
            print(f"ç”Ÿæˆè§†é¢‘é“¾æ¥å¤±è´¥: {e}")
            return []
    
    def download_file(self, url: str, filepath: str, retries: int = 3, progress_callback=None) -> bool:
        """ä¸‹è½½æ–‡ä»¶ï¼Œæ”¯æŒè¿›åº¦å›è°ƒ"""
        # åˆå§‹åŒ–è¿›åº¦æ›´æ–°æ—¶é—´
        if not hasattr(self, '_last_progress_update'):
            self._last_progress_update = 0
            
        for attempt in range(retries):
            try:
                print(f"æ­£åœ¨ä¸‹è½½: {url}")
                
                # åœ¨å¼€å§‹ä¸‹è½½å‰ï¼Œå…ˆå‘é€å¼€å§‹ä¸‹è½½çš„æ¶ˆæ¯
                if progress_callback:
                    filename = os.path.basename(filepath)
                    start_text = (
                        f"ğŸš€ å¼€å§‹ä¸‹è½½: `{filename}`\n"
                        f"ğŸ“¥ æ­£åœ¨è·å–æ–‡ä»¶ä¿¡æ¯..."
                    )
                    try:
                        if asyncio.iscoroutinefunction(progress_callback):
                            try:
                                loop = asyncio.get_running_loop()
                                asyncio.create_task(progress_callback(start_text))
                            except RuntimeError:
                                print(f"è­¦å‘Š: æ— æ³•åœ¨å½“å‰çº¿ç¨‹ä¸­è°ƒç”¨å¼‚æ­¥è¿›åº¦å›è°ƒï¼Œè·³è¿‡å¼€å§‹æ¶ˆæ¯")
                        else:
                            progress_callback(start_text)
                    except Exception as e:
                        print(f"å¼€å§‹ä¸‹è½½æ¶ˆæ¯å›è°ƒå¤±è´¥: {e}")
                
                response = self.session.get(url, timeout=30, stream=True)
                response.raise_for_status()
                
                # è·å–æ–‡ä»¶å¤§å°
                total_size = int(response.headers.get('content-length', 0))
                downloaded_size = 0
                start_time = time.time()
                
                # ç¡®ä¿ç›®å½•å­˜åœ¨
                os.makedirs(os.path.dirname(filepath), exist_ok=True)
                
                with open(filepath, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                            downloaded_size += len(chunk)
                            
                            # è®¡ç®—è¿›åº¦å’Œé€Ÿåº¦
                            if total_size > 0:
                                progress = (downloaded_size / total_size) * 100
                                elapsed_time = time.time() - start_time
                                if elapsed_time > 0:
                                    speed = downloaded_size / elapsed_time / (1024 * 1024)  # MB/s
                                    
                                    # è®¡ç®—é¢„è®¡å‰©ä½™æ—¶é—´
                                    if speed > 0:
                                        remaining_bytes = total_size - downloaded_size
                                        eta_seconds = remaining_bytes / (speed * 1024 * 1024)
                                        mins, secs = divmod(int(eta_seconds), 60)
                                        if mins > 0:
                                            eta_str = f"{mins:02d}:{secs:02d}"
                                        else:
                                            eta_str = f"00:{secs:02d}"
                                    else:
                                        eta_str = "æœªçŸ¥"
                                    
                                    # åˆ›å»ºè¿›åº¦æ–‡æœ¬ï¼ˆå‚è€ƒXå›¾ç‰‡ä¸‹è½½æ ¼å¼ï¼‰
                                    downloaded_mb = downloaded_size / (1024 * 1024)
                                    total_mb = total_size / (1024 * 1024)
                                    filename = os.path.basename(filepath)
                                    
                                    progress_text = (
                                        f"ğŸ“ æ–‡ä»¶: `{filename}`\n"
                                        f"ğŸ’¾ å¤§å°: `{downloaded_mb:.2f}MB / {total_mb:.2f}MB`\n"
                                        f"âš¡ é€Ÿåº¦: `{speed:.2f}MB/s`\n"
                                        f"â³ é¢„è®¡å‰©ä½™: `{eta_str}`\n"
                                        f"ğŸ“Š è¿›åº¦: {self._create_progress_bar(progress)} `{progress:.1f}%`"
                                    )
                                    
                                    # æ™ºèƒ½è¿›åº¦æ›´æ–°ç­–ç•¥
                                    should_update = False
                                    current_time = time.time()
                                    
                                    # 1. å¼ºåˆ¶æ˜¾ç¤ºå…³é”®è¿›åº¦ç‚¹ï¼ˆ25%, 50%, 75%, 100%ï¼‰
                                    if progress >= 25 and not hasattr(self, '_shown_25'):
                                        should_update = True
                                        self._shown_25 = True
                                    elif progress >= 50 and not hasattr(self, '_shown_50'):
                                        should_update = True
                                        self._shown_50 = True
                                    elif progress >= 75 and not hasattr(self, '_shown_75'):
                                        should_update = True
                                        self._shown_75 = True
                                    elif progress >= 99 and not hasattr(self, '_shown_99'):
                                        should_update = True
                                        self._shown_99 = True
                                    
                                    # 2. æ—¶é—´é—´éš”æ›´æ–°ï¼ˆå¦‚æœä¸‹è½½å¾ˆå¿«ï¼Œå‡å°‘é—´éš”ï¼‰
                                    if not should_update and hasattr(self, '_last_progress_update'):
                                        # æ ¹æ®ä¸‹è½½é€Ÿåº¦åŠ¨æ€è°ƒæ•´æ›´æ–°é¢‘ç‡
                                        if speed > 10:  # å¦‚æœé€Ÿåº¦è¶…è¿‡10MB/sï¼Œè®¤ä¸ºæ˜¯å¿«é€Ÿä¸‹è½½
                                            update_interval = 0.1  # 100æ¯«ç§’æ›´æ–°ä¸€æ¬¡
                                        elif speed > 5:  # å¦‚æœé€Ÿåº¦è¶…è¿‡5MB/s
                                            update_interval = 0.2  # 200æ¯«ç§’æ›´æ–°ä¸€æ¬¡
                                        else:
                                            update_interval = 0.5  # 500æ¯«ç§’æ›´æ–°ä¸€æ¬¡
                                        
                                        if current_time - self._last_progress_update >= update_interval:
                                            should_update = True
                                    
                                    # 3. ç¬¬ä¸€æ¬¡æ›´æ–°
                                    elif not hasattr(self, '_last_progress_update'):
                                        should_update = True
                                    
                                    # æ‰§è¡Œè¿›åº¦æ›´æ–°
                                    if should_update and progress_callback:
                                        try:
                                            if asyncio.iscoroutinefunction(progress_callback):
                                                # å¼‚æ­¥å›è°ƒ - åˆ›å»ºæ–°ä»»åŠ¡è€Œä¸æ˜¯ä½¿ç”¨run_coroutine_threadsafe
                                                try:
                                                    loop = asyncio.get_running_loop()
                                                    asyncio.create_task(progress_callback(progress_text))
                                                except RuntimeError:
                                                    # å¦‚æœæ²¡æœ‰è¿è¡Œçš„äº‹ä»¶å¾ªç¯ï¼Œå°è¯•åŒæ­¥è°ƒç”¨
                                                    print(f"è­¦å‘Š: æ— æ³•åœ¨å½“å‰çº¿ç¨‹ä¸­è°ƒç”¨å¼‚æ­¥è¿›åº¦å›è°ƒï¼Œè·³è¿‡æ›´æ–°")
                                            else:
                                                # åŒæ­¥å›è°ƒ
                                                progress_callback(progress_text)
                                            self._last_progress_update = current_time
                                        except Exception as e:
                                            print(f"è¿›åº¦å›è°ƒå¤±è´¥: {e}")
                
                # æ¸…ç†è¿›åº¦æ ‡è®°
                for attr in ['_shown_25', '_shown_50', '_shown_75', '_shown_99']:
                    if hasattr(self, attr):
                        delattr(self, attr)
                
                # ç¡®ä¿æœ€åå‘é€100%è¿›åº¦ï¼ˆå¦‚æœä¸‹è½½å¾ˆå¿«å¯èƒ½è·³è¿‡äº†æœ€åçš„è¿›åº¦æ›´æ–°ï¼‰
                if progress_callback and total_size > 0:
                    try:
                        final_size_mb = os.path.getsize(filepath) / (1024 * 1024)
                        filename = os.path.basename(filepath)

                        # åªå‘é€ä¸€æ¬¡æœ€ç»ˆçš„100%è¿›åº¦æ¶ˆæ¯
                        final_progress_text = (
                            f"ğŸ“ æ–‡ä»¶: `{filename}`\n"
                            f"ğŸ’¾ å¤§å°: `{final_size_mb:.2f}MB / {final_size_mb:.2f}MB`\n"
                            f"âš¡ é€Ÿåº¦: `å®Œæˆ`\n"
                            f"â³ é¢„è®¡å‰©ä½™: `00:00`\n"
                            f"ğŸ“Š è¿›åº¦: {self._create_progress_bar(100)} `100.0%`"
                        )

                        print(f"ğŸ¯ å‘é€æœ€ç»ˆè¿›åº¦æ¶ˆæ¯: {filename}")

                        if asyncio.iscoroutinefunction(progress_callback):
                            try:
                                loop = asyncio.get_running_loop()
                                # ç­‰å¾…æœ€ç»ˆè¿›åº¦æ¶ˆæ¯å‘é€å®Œæˆ
                                asyncio.create_task(progress_callback(final_progress_text))
                                self._last_progress_update = 0
                            except RuntimeError:
                                print(f"è­¦å‘Š: æ— æ³•åœ¨å½“å‰çº¿ç¨‹ä¸­è°ƒç”¨å¼‚æ­¥è¿›åº¦å›è°ƒï¼Œè·³è¿‡æœ€ç»ˆè¿›åº¦æ¶ˆæ¯")
                        else:
                            progress_callback(final_progress_text)
                            self._last_progress_update = 0

                    except Exception as e:
                        print(f"æœ€ç»ˆè¿›åº¦å›è°ƒå¤±è´¥: {e}")

                # å¢åŠ å»¶è¿Ÿï¼Œç¡®ä¿æ‰€æœ‰è¿›åº¦æ¶ˆæ¯éƒ½è¢«å¤„ç†å®Œæ¯•
                print(f"â³ ç­‰å¾…è¿›åº¦æ¶ˆæ¯å¤„ç†å®Œæˆ...")
                time.sleep(1.0)  # å¢åŠ å»¶è¿Ÿåˆ°1ç§’ï¼Œç¡®ä¿è¿›åº¦æ¶ˆæ¯è¢«å¤„ç†
                
                print(f"ä¸‹è½½æˆåŠŸ: {filepath}")
                return True
                
            except Exception as e:
                print(f"ä¸‹è½½å¤±è´¥ (å°è¯• {attempt + 1}/{retries}): {e}")
                if attempt < retries - 1:
                    time.sleep(2)
        
        return False
    
    def _create_progress_bar(self, percent: float, length: int = 20) -> str:
        """åˆ›å»ºè¿›åº¦æ¡"""
        filled_length = int(length * percent / 100)
        return "â–ˆ" * filled_length + "â–‘" * (length - filled_length)
    
    def clean_filename(self, filename: str) -> str:
        """æ¸…ç†æ–‡ä»¶å"""
        # ç§»é™¤éæ³•å­—ç¬¦
        filename = re.sub(r'[<>:"/\\|?*]', '', filename)
        # é™åˆ¶é•¿åº¦
        if len(filename) > 100:
            filename = filename[:100]
        return filename or "untitled"
    
    def download_note(self, url: str, download_dir: str = "./downloads", progress_callback=None) -> dict:
        """ä¸‹è½½ç¬”è®°å†…å®¹ï¼Œæ”¯æŒè¿›åº¦å›è°ƒ"""
        try:
            print(f"å¼€å§‹å¤„ç†: {url}")
            
            # æå–ç¬”è®°ID
            note_id = self.extract_note_id(url)
            if not note_id:
                print("æ— æ³•æå–ç¬”è®°ID")
                return {"success": False, "error": "æ— æ³•æå–ç¬”è®°ID"}
            
            # è·å–é¡µé¢æ•°æ®ï¼ˆä½¿ç”¨å±•å¼€åçš„é•¿é“¾æ¥ä»¥ç¡®ä¿å‘½ä¸­ç›®æ ‡ç¬”è®°ï¼‰
            expanded_for_page = self._expand_short_url(url) or url
            print(f"ğŸ”— ä½¿ç”¨URLè·å–é¡µé¢æ•°æ®: {expanded_for_page}")
            data = self.get_page_data(expanded_for_page)
            if not data:
                print("è·å–é¡µé¢æ•°æ®å¤±è´¥")
                return {"success": False, "error": "è·å–é¡µé¢æ•°æ®å¤±è´¥"}
            
            # æå–ç¬”è®°ä¿¡æ¯
            note = self.extract_note_info(data, note_id)
            if not note:
                print("æå–ç¬”è®°ä¿¡æ¯å¤±è´¥")
                return {"success": False, "error": "æå–ç¬”è®°ä¿¡æ¯å¤±è´¥"}
            
            # è·å–æ ‡é¢˜å’Œä½œè€…
            title = note.get('displayTitle', note.get('title', note.get('desc', 'untitled')))
            title = self.clean_filename(title)
            author = note.get('user', {}).get('nickname', 'æœªçŸ¥ä½œè€…')
            
            # åˆ¤æ–­å†…å®¹ç±»å‹
            note_type = note.get('type', 'normal')
            
            print(f"ğŸ” æå–çš„æ ‡é¢˜: {title}")
            print(f"ğŸ” æå–çš„ä½œè€…: {author}")
            print(f"ğŸ” ç¬”è®°ç±»å‹: {note_type}")
            print(f"ğŸ” ç¬”è®°é”®: {list(note.keys())}")
            
            # æ ¹æ®å†…å®¹ç±»å‹ç”Ÿæˆä¸‹è½½é“¾æ¥
            files = []
            if note_type == 'video':
                urls = self.generate_video_url(note)
                media_type = 'video'
            else:
                urls = self.generate_image_urls(note)
                media_type = 'image'
            
            # ä¸‹è½½ç›®å½•
            safe_title = self.clean_filename(title)
            base_dir = os.path.join(download_dir, f"{note_id}_{safe_title}")
            os.makedirs(base_dir, exist_ok=True)
            
            total_size = 0
            for idx, media_url in enumerate(urls, start=1):
                ext = '.mp4' if media_type == 'video' else '.png'
                # ä½¿ç”¨æ ‡é¢˜ä½œä¸ºæ–‡ä»¶åï¼Œå¤šä¸ªæ–‡ä»¶æ—¶æ·»åŠ åºå·
                if len(urls) == 1:
                    filename = f"{safe_title}{ext}"
                else:
                    filename = f"{safe_title}_{idx}{ext}"
                filepath = os.path.join(base_dir, filename)
                
                # ä¸‹è½½æ–‡ä»¶ï¼ˆå¸¦è¿›åº¦å›è°ƒï¼‰
                success = self.download_file(media_url, filepath, progress_callback=progress_callback)
                if success:
                    file_size = os.path.getsize(filepath)
                    total_size += file_size
                    files.append({
                        'path': filepath,
                        'size': file_size,
                        'type': media_type
                    })
            
            # ç­‰å¾…æ‰€æœ‰è¿›åº¦æ¶ˆæ¯å¤„ç†å®Œæ¯•ï¼Œç¡®ä¿æ±‡æ€»ä¿¡æ¯åœ¨è¿›åº¦æ¶ˆæ¯ä¹‹åæ˜¾ç¤º
            if progress_callback:
                print("â³ ç­‰å¾…æ‰€æœ‰è¿›åº¦æ¶ˆæ¯å¤„ç†å®Œæˆ...")
                time.sleep(2.0)  # ç­‰å¾…2ç§’ï¼Œç¡®ä¿æ‰€æœ‰è¿›åº¦æ¶ˆæ¯éƒ½è¢«å¤„ç†
            
            # ç§»é™¤å»¶è¿Ÿï¼Œè®©main.pyç»Ÿä¸€å¤„ç†å®Œæˆæ¶ˆæ¯
            
            # è¿”å›ä¸‹è½½ç»“æœ
            return {
                "success": True,
                "title": title,
                "author": author,
                "note_id": note_id,
                "media_type": media_type,
                "files": files,
                "total_size": total_size,
                "save_dir": base_dir
            }
            
        except Exception as e:
            print(f"ä¸‹è½½ç¬”è®°å¤±è´¥: {e}")
            return {"success": False, "error": str(e)}

def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='å°çº¢ä¹¦å†…å®¹ä¸‹è½½å™¨')
    parser.add_argument('urls', nargs='*', help='è¦ä¸‹è½½çš„å°çº¢ä¹¦é“¾æ¥')
    parser.add_argument('-d', '--dir', default='./downloads', help='ä¸‹è½½ç›®å½•')
    parser.add_argument('-c', '--cookie', help='å°çº¢ä¹¦ Cookieï¼ˆå¯é€‰ï¼‰')

    args = parser.parse_args()

    downloader = XiaohongshuDownloader()

    # å¦‚æœæä¾›äº† Cookieï¼Œæ·»åŠ åˆ°è¯·æ±‚å¤´
    if args.cookie:
        downloader.session.headers['Cookie'] = args.cookie

    # å¦‚æœæ²¡æœ‰é€šè¿‡å‘½ä»¤è¡Œæä¾›URLï¼Œä½¿ç”¨äº¤äº’å¼è¾“å…¥
    urls = args.urls
    if not urls:
        print("è¯·è¾“å…¥å°çº¢ä¹¦é“¾æ¥ï¼ˆè¾“å…¥ 'quit' é€€å‡ºï¼‰:")
        while True:
            url = input("URL: ").strip()
            if url.lower() == 'quit':
                break
            if url:
                urls.append(url)

    if not urls:
        print("æ²¡æœ‰æä¾›ä»»ä½•é“¾æ¥")
        return

    print(f"å‡†å¤‡ä¸‹è½½ {len(urls)} ä¸ªé“¾æ¥åˆ°ç›®å½•: {args.dir}")

    success_count = 0
    for i, url in enumerate(urls, 1):
        try:
            print(f"\n[{i}/{len(urls)}] å¤„ç†é“¾æ¥: {url}")
            
            # åˆ›å»ºç®€å•çš„è¿›åº¦å›è°ƒå‡½æ•°
            def progress_callback(text):
                print(f"ğŸ“± è¿›åº¦: {text}")
            
            result = downloader.download_note(url, args.dir, progress_callback)
            if result.get("success"):
                success_count += 1
                print(f"âœ… ä¸‹è½½æˆåŠŸ: {result.get('title', 'æœªçŸ¥æ ‡é¢˜')}")
            else:
                print(f"âŒ ä¸‹è½½å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            
            time.sleep(2)  # é¿å…è¯·æ±‚è¿‡å¿«
        except Exception as e:
            print(f"å¤„ç†é“¾æ¥å¤±è´¥ {url}: {e}")

    print(f"\nå®Œæˆï¼æˆåŠŸä¸‹è½½ {success_count}/{len(urls)} ä¸ªé“¾æ¥")

if __name__ == "__main__":
    main()

